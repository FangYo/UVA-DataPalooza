{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Data-Acquisition\" data-toc-modified-id=\"Data-Acquisition-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Acquisition</a></span></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preprocessing</a></span></li><li><span><a href=\"#Split-Training-&amp;-Test-Data\" data-toc-modified-id=\"Split-Training-&amp;-Test-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Split Training &amp; Test Data</a></span></li><li><span><a href=\"#Create-Data-Visualization-Method\" data-toc-modified-id=\"Create-Data-Visualization-Method-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create Data Visualization Method</a></span></li><li><span><a href=\"#Select-Training-Data-Subset\" data-toc-modified-id=\"Select-Training-Data-Subset-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Select Training Data Subset</a></span></li><li><span><a href=\"#Visualize-Data\" data-toc-modified-id=\"Visualize-Data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Visualize Data</a></span></li><li><span><a href=\"#Create-CNN-Model-Method\" data-toc-modified-id=\"Create-CNN-Model-Method-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Create CNN Model Method</a></span></li><li><span><a href=\"#Instantiate-Model\" data-toc-modified-id=\"Instantiate-Model-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Instantiate Model</a></span></li><li><span><a href=\"#Set-Training-Hyperparameters\" data-toc-modified-id=\"Set-Training-Hyperparameters-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Set Training Hyperparameters</a></span></li><li><span><a href=\"#Create-Callback-Settings\" data-toc-modified-id=\"Create-Callback-Settings-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Create Callback Settings</a></span></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Train Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.metrics import classification_report\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.kaggle.com/rhammell/planesnet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://www.kaggle.com/rhammell/planesnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to planesnet image folder.\n",
    "IMAGE_PATH = 'C:/Users/596596/Documents/GitHub/UVA-DataPalooza/planesnet/'\n",
    "file_paths = glob.glob(path.join(IMAGE_PATH, '*.png'))\n",
    "\n",
    "# Load the images into a single variable and convert to a numpy array.\n",
    "images = [imageio.imread(path) for path in file_paths]\n",
    "images = np.asarray(images)\n",
    "\n",
    "# Get the dimensions of the image.  This image_size array will let us know the dimensions of the images. If we print this \n",
    "# variable, we learn that the dimensions of the images are [20, 20, 3]. This means that each image in the dataset has 20 \n",
    "# rows, 20 columns, and a depth of 3 (or 3 channels, Red, Green, and Blue). These numbers define the spatial resolution of \n",
    "# the image.\n",
    "image_size = np.asarray([images.shape[1], images.shape[2], images.shape[3]])\n",
    "print(image_size)\n",
    "\n",
    "# Scale the image.  BThe images we are working with are 8-bit. This means that each pixel in the image is one of 256 (2⁸ = 256)\n",
    "# possible values. While some machine learning algorithms can handle having relatively large pixel values, most methods perform\n",
    "# optimally (train within our lifetimes) when small, floating point values are processed. Hence we divide by 255 \n",
    "# (0 is a possible pixel value as well, so 255 is actually the maximum value found within our data) to scale our data between \n",
    "# 0–1. So, after this step, a value that was represented by an integer of 128, would now instead be represented by a floating \n",
    "# point value of 128/255 = ~0.502. It is important to note that the appearance of the images will be fundamentally unaltered \n",
    "# after this step.\n",
    "images = images / 255\n",
    "\n",
    "# Read the labels from the filenames.  These labels were manually annotated by a human being. Each 20 by 20 image was reviewed, \n",
    "# and given a “1” (True) if it contained an airplane and a “0” (False) if it did not contain an airplane. We can extract these \n",
    "# labels by reading in the first character in the image filename. For example, in the image filename \n",
    "# “0__20140723_181317_0905__-122.14328662_37.697282118.png”, the very first “0” is indicating to us that this image does not \n",
    "# contain an airplane.\n",
    "n_images = images.shape[0]\n",
    "labels = np.zeros(n_images)\n",
    "for i in range(n_images):\n",
    "    filename = path.basename(file_paths[i])[0]\n",
    "    labels[i] = int(filename[0])\n",
    "    \n",
    "# Now we images and their corresponding labels. In the classic supervised machine learning terminiology, we consider \n",
    "# the images to be “X” and the labels to be “y”. The machine learning algorithm is going to find a function “f” such that for\n",
    "# any given image, y = f(X). In other words, we are going to take the 1,200 (20 x 20 x 3 = 1,200) X values, run them through a \n",
    "# function, f, and predict one singular value, y, that represents a classification of either “plane” or “not plane”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Training & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and training sets.  This practice is important, because it is the only way to evaluate your model in \n",
    "# an unbiased way. Basically, you want your model to learn on the training set, (usually about 90% of all of the images you \n",
    "# have available), and then report back its accuracy by evaluating it on the test set (the remaining 10%).  Generally, a model \n",
    "# that only performs well on data that it was trained on is not useful or interesting, and is described as “over-fit”. \n",
    "# Over-fitting is the equivalent of the model memorizing the labels. It would be like a student who learns that 2 + 2 = 4, and \n",
    "# then assumes that every addition problem they see is equal to 4.  They have not actually learned how to perform addition, \n",
    "# rather they have just memorized an output. We want our model to generalize a concept. It needs to be able to grab an image \n",
    "# with an unknown label and accurately predict if it contains an airplane or not, regardless of whether or not the model has \n",
    "# seen the image before. We can best simulate this scenario by creating a test set, as shown below. \n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "\n",
    "# Split at the given index\n",
    "split_index = int(TRAIN_TEST_SPLIT * n_images)\n",
    "shuffled_indices = np.random.permutation(n_images)\n",
    "train_indices = shuffled_indices[0:split_index]\n",
    "test_indices = shuffled_indices[split_index:]\n",
    "\n",
    "# Split the images and the labels (Optimize, Fold)\n",
    "x_train = images[train_indices, :, :]\n",
    "y_train = labels[train_indices]\n",
    "x_test = images[test_indices, :, :]\n",
    "y_test = labels[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot positive and negative image examples for us. By “positive” we mean data with a label of “1” or “True”,\n",
    "# and by “negative” we mean data with a label of “0” or “False”. We need negative examples (i.e. images that do not contain \n",
    "# airplanes), because otherwise the model would not have any reference point and likely assume that the mere presence of an \n",
    "# image is indicative that it contains an airplane. The inner workings of the visualize_data function create two rows of images \n",
    "# where some number of positive examples are on the top, and the same number of negative examples are on the bottom. The titles \n",
    "# above them indicate what their label is.\n",
    "def visualize_data(positive_images, negative_images):\n",
    "    figure = plt.figure(figsize=(15,5))\n",
    "    count = 0\n",
    "    for i in range(positive_images.shape[0]):\n",
    "        count += 1\n",
    "        figure.add_subplot(2, positive_images.shape[0], count)\n",
    "        plt.imshow(positive_images[i, :, :])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"1\")\n",
    "\n",
    "        figure.add_subplot(1, negative_images.shape[0], count)\n",
    "        plt.imshow(negative_images[i, :, :])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"0\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Training Data Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of positive and negative examples to show\n",
    "N_TO_VISUALIZE = 10\n",
    "\n",
    "# Select the first N positive examples\n",
    "positive_example_indices = (y_train == 1)\n",
    "positive_examples = x_train[positive_example_indices, :, :]\n",
    "positive_examples = positive_examples[0:N_TO_VISUALIZE, :, :]\n",
    "\n",
    "# Select the first N negative examples\n",
    "negative_example_indices = (y_train == 0)\n",
    "negative_examples = x_train[negative_example_indices, :, :]\n",
    "negative_examples = negative_examples[0:N_TO_VISUALIZE, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images only have a resolution of 20px by 20px and at this poor resolution we can somewhat pick out the airplanes in \n",
    "# the positive examples, and the lack of airplanes in the negative images. It seems we have our work cut out for us! That \n",
    "# being said, let’s list out some more detailed observations we might make from this data. There are partial airplanes in \n",
    "# the negative examples. The positive examples appear to contain airplanes of different sizes. Sometimes the plane occupies\n",
    "# 16–18 pixels, other times only 8–10 pixels. There are varied atmospheric conditions present in the images. If you spend \n",
    "# more time looking at these examples, you will probably notice even more intricacies about the data. The devil is often \n",
    "# in the details, so it is worth your time to get to know your data as well as possible. \n",
    "# 1. There are partial airplanes in the negative examples\n",
    "# 2. The positive examples appear to contain airplanes of different sizes. \n",
    "# 3. Sometimes the plane occupies 16–18 pixels, other times only 8–10 pixels\n",
    "# 4. There are varied atmospheric conditions present in the images visualize_data(positive_examples, negative_examples)\n",
    "visualize_data(positive_examples, negative_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create CNN Model Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(size):\n",
    "    # INPUTS\n",
    "    # size     - size of the input images\n",
    "    # N_LAYERS - number of layers\n",
    "    # OUTPUTS\n",
    "    # model    - compiled CNN\n",
    "\n",
    "    # Define hyperparamters\n",
    "    N_LAYERS = 4\n",
    "    MIN_NEURONS = 20\n",
    "    MAX_NEURONS = 120\n",
    "    KERNEL = (3, 3)\n",
    "\n",
    "    # Determine the # of neurons in each convolutional layer\n",
    "    steps = np.floor(MAX_NEURONS / (N_LAYERS + 1))\n",
    "    nuerons = np.arange(MIN_NEURONS, MAX_NEURONS, steps)\n",
    "    nuerons = nuerons.astype(np.int32)\n",
    "\n",
    "    # Define a model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add convolutional layers\n",
    "    for i in range(0, N_LAYERS):\n",
    "        if i == 0:\n",
    "            shape = (size[0], size[1], size[2])\n",
    "            model.add(Conv2D(nuerons[i], KERNEL, input_shape=shape))\n",
    "        else:\n",
    "            model.add(Conv2D(nuerons[i], KERNEL))\n",
    "\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    # Add max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(MAX_NEURONS))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Print a summary of the model\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn(size=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Callback Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data = (x_test, y_test), callbacks=[csv_logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uva-datapalooza)",
   "language": "python",
   "name": "uva-datapalooza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "76px",
    "width": "183px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
